{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.nn.utils import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(translator,stop_words,ps,**kwargs): # obtains a word to index mapping as well\n",
    "    count = 0\n",
    "    vocabulary = Counter()\n",
    "    w2i = {}\n",
    "    for label,fname in kwargs.items():\n",
    "        with open(fname+'_cleaned','w') as ft:\n",
    "            with open(fname) as fs:\n",
    "                for line in fs:\n",
    "                    count+=1\n",
    "                    label = line[0]\n",
    "                    review = line[2:]\n",
    "                    label = line[0]\n",
    "                    review = line[2:]\n",
    "                    sents = review.strip().split('.')\n",
    "                    sents = [[ps.stem(w) for w in word_tokenize(s.translate(translator)) if w not in stop_words] \\\n",
    "                             for s in sents if len(s)>1]\n",
    "                    words = sum(sents,[])\n",
    "                    for w in words:\n",
    "                        vocabulary[w] = 1\n",
    "                    rev = '.'.join([' '.join(s) for s in sents])\n",
    "                    ft.write(label+','+rev)\n",
    "                    ft.write('\\n')\n",
    "                    if count%1000000==0:  \n",
    "                        print('cleaned reviews: ',count)\n",
    "                        \n",
    "    count = 1\n",
    "    for w in vocabulary:\n",
    "        w2i[w]=count\n",
    "        count+=1\n",
    "    return w2i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "w2i = clean(translator,stop_words,ps,file='../Data/test_s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2i)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2tensor(review,w2i):\n",
    "    out = [[w2i[w] for w in sents.split()] for sents in review if len(sents)>0] \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingDataset(fname,w2i):  # dictionary of list of tuples (rev,label)\n",
    "    dataset = {}\n",
    "    with open(fname+'_cleaned') as fs:\n",
    "        for line in fs:\n",
    "            label = int(line[0])\n",
    "            review = line[2:]\n",
    "            temp = review.strip().split('.')\n",
    "            length = len(temp)\n",
    "            if length not in dataset:\n",
    "                dataset[length] = []\n",
    "            encoded_review = text2tensor(temp,w2i)\n",
    "            dataset[length].append((encoded_review,label))\n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = creatingDataset('../Data/test_s.csv',w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n",
      "3 13\n",
      "23 1\n",
      "2 4\n",
      "9 1\n",
      "5 3\n",
      "11 1\n"
     ]
    }
   ],
   "source": [
    "for key in train_dataset:\n",
    "    print(key,len(train_dataset[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([6, 3, 23, 2, 9, 5, 11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatches(dataset,batch_size): # generator implementation \n",
    "    batch = [] # return a batch of datapoints based on batch_size\n",
    "    lengths = list(dataset.keys())\n",
    "    lengths.sort(reverse=True)\n",
    "    size = 0\n",
    "    sent_length = []\n",
    "    for l in lengths:\n",
    "        for doc in dataset[l]:\n",
    "            if len(batch)>0:\n",
    "                curr_len = len(batch[-1][0])\n",
    "            else:\n",
    "                curr_len = l\n",
    "            diff = curr_len - len(doc[0]) \n",
    "            if diff<=2 and diff>0:\n",
    "                size+=1\n",
    "                batch.append(doc)\n",
    "                sent_length.append(len(doc[0]))\n",
    "            elif diff==0:\n",
    "                batch.append(doc)\n",
    "                sent_length.append(len(doc[0]))\n",
    "                size+=1\n",
    "            else:\n",
    "                if len(batch)>0:\n",
    "                    yield (batch,sent_length)\n",
    "                batch = [doc]\n",
    "                sent_length = [len(doc[0])]\n",
    "                size = 1\n",
    "                \n",
    "            if size==batch_size:\n",
    "                yield (batch,sent_length)\n",
    "                batch = []\n",
    "                sent_length = []\n",
    "                size = 0\n",
    "    yield (batch,sent_length)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeSentences(batch,lengths):\n",
    "    sent = []\n",
    "    label = []\n",
    "    for review,l in batch:\n",
    "        sent+=review\n",
    "        label.append(l)\n",
    "    return sent,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEnc = wordEncoder(644,15,20,15,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentEnc = sentenceEncoder(15,20,15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 33, 20])\n",
      "tensor([21, 20, 15,  7, 13, 18,  0,  1,  2,  4,  3, 19, 10,  9, 17, 14,  5, 11,\n",
      "        16,  8, 12,  6])\n",
      "torch.Size([1, 22, 15])\n",
      "torch.Size([22, 15])\n",
      "tensor([[[0.4688, 0.4144],\n",
      "         [0.4674, 0.4158],\n",
      "         [0.4672, 0.4146],\n",
      "         [0.4668, 0.4159]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "for batch,lengths in createBatches(train_dataset,4):\n",
    "    if len(lengths)<3:\n",
    "        continue\n",
    "    sent,label = mergeSentences(batch,lengths)\n",
    "    sentence_length = [len(s) for s in sent]\n",
    "    sent = np.array(list(itertools.zip_longest(*sent, fillvalue=0))).T\n",
    "    X = torch.from_numpy(sent)\n",
    "    X_lengths = torch.LongTensor(sentence_length)\n",
    "    X,X_lengths,mapped_index = sortbylength(X,X_lengths)\n",
    "    batch_size = len(sentence_length)\n",
    "    \n",
    "    sent_out = wordEnc(X,X_lengths,batch_size)\n",
    "    sent_out = sent_out.squeeze()[mapped_index,:]\n",
    "    \n",
    "    curr_length = lengths[0]\n",
    "    \n",
    "    review_batch = torch.Tensor()\n",
    "    \n",
    "    r = 0\n",
    "    c = sent_out.shape[1]\n",
    "    for l in lengths:\n",
    "        if l==curr_length:\n",
    "            review_batch = torch.cat((review_batch,sent_out[r:r+l,:]))\n",
    "            r+=l\n",
    "        else:\n",
    "            diff = curr_length-l\n",
    "            review_batch = torch.cat((review_batch,sent_out[r:r+l,:],torch.zeros(diff,c)))\n",
    "            r+=l\n",
    "            \n",
    "    review_batch = review_batch.view(len(lengths),-1,c)\n",
    "    \n",
    "    output = sentEnc(review_batch,torch.LongTensor(lengths),len(lengths))\n",
    "    \n",
    "    print(output)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_out = sent_out.squeeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2259,  0.1208, -0.1167,  0.2175,  0.0648, -0.0127, -0.1858, -0.1479,\n",
       "         -0.2402,  0.0225,  0.1729, -0.0833,  0.0250, -0.1427, -0.0821],\n",
       "        [ 0.1890,  0.1215, -0.2516,  0.2067,  0.0165,  0.0355, -0.1486, -0.1060,\n",
       "         -0.3151,  0.0328,  0.1289, -0.0100,  0.0554, -0.0558,  0.0320],\n",
       "        [ 0.2342,  0.0826, -0.0822,  0.0912, -0.0436, -0.0420, -0.2195, -0.0939,\n",
       "         -0.3350,  0.0054,  0.1092,  0.0267,  0.0347, -0.0588,  0.1323],\n",
       "        [ 0.1675,  0.0539, -0.1533,  0.1286,  0.0015, -0.0280, -0.1306, -0.1284,\n",
       "         -0.2468,  0.1079,  0.0877,  0.0684,  0.0168,  0.0053,  0.0494],\n",
       "        [ 0.2044,  0.1118, -0.1821,  0.1809, -0.0049,  0.0298, -0.2043, -0.1616,\n",
       "         -0.2614,  0.0036,  0.1073, -0.0557,  0.0031, -0.0318, -0.0502]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "sent = np.array(list(itertools.zip_longest(*sent, fillvalue=0))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = torch.from_numpy(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 5, 5]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_idx = 0\n",
    "embed = nn.Embedding(5, 10, padding_idx=padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9230,  0.6575, -1.4323, -0.8788,  0.8231,  0.5026,  0.8340,  1.1535,\n",
       "         -0.9093, -0.5471],\n",
       "        [-0.3955, -1.6489,  1.7715,  1.4298,  1.9349, -0.1394, -0.9060, -0.1989,\n",
       "         -0.5451,  0.9496]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor([1,2],dtype=torch.long)\n",
    "embed(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordEncoder(nn.Module):\n",
    "    def __init__(self,input_size,encoding_size,hidden_size,output_size,padding_idx):\n",
    "        super(wordEncoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = True\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, encoding_size, padding_idx=padding_idx)\n",
    "        self.e2i = nn.Linear(encoding_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.h2o = nn.Linear(2*hidden_size, output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.u_w = nn.Parameter(torch.rand(output_size)) # word context\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, X, X_lengths, batch_size):\n",
    "        \n",
    "        self.hidden = self.initHidden(batch_size)\n",
    "        X = self.embedding(X)\n",
    "        X = self.e2i(X)\n",
    "\n",
    "        X = rnn.pack_padded_sequence(X, X_lengths, batch_first=True)\n",
    "\n",
    "        X, self.hidden = self.gru(X, self.hidden)\n",
    "\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "\n",
    "        H = torch.unbind(X,dim=0)\n",
    "        X = self.h2o(X)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        Y = torch.unbind(X,dim=0)\n",
    "        \n",
    "        Y_1 = torch.Tensor()\n",
    "        for i in range(X_lengths.shape[0]):\n",
    "            x = self.softmax(torch.sum(Y[i][:X_lengths[i].item()]*self.u_w,dim=1)).view(-1,1)\n",
    "            Y_1 = torch.cat((Y_1,torch.sum(H[i][:X_lengths[i].item()]*x,dim=0).view(1,1,-1)),dim=1)\n",
    "        \n",
    "        return Y_1\n",
    "        \n",
    "    def initHidden(self,batch_size):\n",
    "         return torch.zeros(2, batch_size, self.hidden_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.LongTensor(4,5).random_(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = torch.LongTensor([5,5,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_encoder = wordEncoder(10,15,20,15,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "out = word_encoder(inp,length,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0998, -0.1925,  0.1959, -0.2869, -0.0759, -0.3332,  0.0517,\n",
       "           0.2547,  0.2556,  0.0702,  0.2077, -0.2388,  0.0432,  0.2740,\n",
       "           0.1155],\n",
       "         [ 0.0053, -0.2452,  0.1693, -0.1561,  0.0096, -0.2666,  0.0875,\n",
       "           0.1585,  0.2412,  0.1068,  0.1697, -0.2195,  0.1377,  0.0993,\n",
       "           0.0125],\n",
       "         [ 0.0769, -0.0422,  0.1295, -0.1372,  0.0156, -0.3321,  0.0245,\n",
       "           0.2075,  0.1447,  0.1233,  0.1157, -0.2569,  0.2089,  0.0249,\n",
       "           0.0300],\n",
       "         [-0.1507, -0.2629,  0.1344, -0.1698, -0.0832, -0.1477,  0.1191,\n",
       "           0.1807,  0.1812,  0.0761,  0.1205, -0.2088, -0.0027,  0.1596,\n",
       "           0.0796]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1 = torch.LongTensor(3,5).random_(1,10)\n",
    "length_1 = torch.LongTensor([5,5,5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = word_encoder(inp_1,length_1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 15])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 15])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros(1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = torch.cat((out_1.squeeze(),z)).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 15])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 15])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_s = torch.cat((out,out_1),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 15])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 15])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 15])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentenceEncoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,repr_size,output_size):\n",
    "        super(sentenceEncoder,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.g2r = nn.Linear(2*hidden_size,repr_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.u_s = nn.Parameter(torch.rand(repr_size)) # sentence context\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.r2o = nn.Linear(2*hidden_size,output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X, X_lengths, batch_size):\n",
    "        self.hidden = self.initHidden(batch_size)\n",
    "\n",
    "        X = rnn.pack_padded_sequence(X, X_lengths, batch_first=True)\n",
    "\n",
    "        X, self.hidden = self.gru(X, self.hidden)\n",
    "\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "\n",
    "        H = torch.unbind(X,dim=0) # hidden state obtained from each sentence    \n",
    "        \n",
    "        X = self.g2r(X)\n",
    "        X = self.tanh(X)\n",
    "        \n",
    "        Y = torch.unbind(X,dim=0)\n",
    "        \n",
    "        Y_1 = torch.Tensor()\n",
    "        for i in range(X_lengths.shape[0]):\n",
    "            x = self.softmax(torch.sum(Y[i][:X_lengths[i].item()]*self.u_s,dim=1)).view(-1,1)\n",
    "            Y_1 = torch.cat((Y_1,torch.sum(H[i][:X_lengths[i].item()]*x,dim=0).view(1,1,-1)),dim=1)\n",
    "        \n",
    "        output = self.r2o(Y_1)\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def initHidden(self,batch_size):\n",
    "         return torch.zeros(2, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_enc = sentenceEncoder(15,20,15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_s_length = torch.LongTensor([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5318, 0.5057],\n",
       "         [0.5416, 0.5014]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_enc(input_s,inp_s_length,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp (4,5), inp_1 (3,5), length (5,5,4,3), length_1 (5,5,5), \n",
    "len_sent = torch.LongTensor([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = torch.cat((inp,inp_1),dim=0)\n",
    "all_sent_len = torch.cat((length,length_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent[2,4] = 0\n",
    "all_sent[3,4] = 0\n",
    "all_sent[3,3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 8, 3, 2],\n",
       "        [8, 7, 7, 5, 8],\n",
       "        [9, 7, 6, 9, 0],\n",
       "        [1, 1, 8, 0, 0],\n",
       "        [8, 2, 2, 4, 3],\n",
       "        [7, 5, 1, 3, 8],\n",
       "        [1, 7, 6, 7, 3]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 4, 3, 5, 5, 5])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.LongTensor([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating sentences from all reviews in a batch and then sorting them based on length would change the order\n",
    "# to keep track of the sequence of the sentences we need to remember the original mapping\n",
    "# this routine keeps track of the sequence of the sentences among all the reviews\n",
    "# need when passing to the sentence encoder...\n",
    "\n",
    "def originalMap(indices):  \n",
    "    count = 0\n",
    "    m = {}\n",
    "    for i in indices:\n",
    "        m[i.item()] = count\n",
    "        count+=1\n",
    "\n",
    "    m_p = []    \n",
    "    for i,val in sorted(m.items(),key=lambda x:x[0]):\n",
    "        m_p.append(val)\n",
    "\n",
    "    return torch.LongTensor(m_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortbylength(all_sent,all_sent_len):\n",
    "    sorted_lengths, indices = torch.sort(all_sent_len,descending=True)\n",
    "    mapped_index = originalMap(indices)\n",
    "    return all_sent[torch.LongTensor(indices),:],sorted_lengths,mapped_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,X_lengths,mapped_index = sortbylength(all_sent,all_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = (all_sent,all_sent_len,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 5])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEnc = wordEncoder(644,15,20,15,0)\n",
    "sentEnc = sentenceEncoder(40,20,15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(wordEnc,sentEnc,train_dataset,batch_size=4,epochs=1,learning_rate=0.001):\n",
    "    \n",
    "    wordEnc_optimizer = optim.Adam(wordEnc.parameters(), lr=learning_rate)\n",
    "    sentEnc_optimizer = optim.Adam(sentEnc.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for batch,lengths in createBatches(train_dataset,4):\n",
    "            if len(lengths)<3:\n",
    "                continue\n",
    "            sent,label = mergeSentences(batch,lengths)\n",
    "            label = torch.LongTensor(label)\n",
    "            print(label)\n",
    "            sentence_length = [len(s) for s in sent]\n",
    "            sent = np.array(list(itertools.zip_longest(*sent, fillvalue=0))).T\n",
    "            X = torch.from_numpy(sent)\n",
    "            X_lengths = torch.LongTensor(sentence_length)\n",
    "            X,X_lengths,mapped_index = sortbylength(X,X_lengths)\n",
    "            batch_size = len(sentence_length)\n",
    "\n",
    "            sent_out = wordEnc(X,X_lengths,batch_size)\n",
    "            print('output from word encoder obtained')\n",
    "            print(sent_out.shape)\n",
    "            \n",
    "            sent_out = sent_out.squeeze()[mapped_index,:]\n",
    "\n",
    "            curr_length = lengths[0]\n",
    "\n",
    "            review_batch = torch.Tensor()\n",
    "\n",
    "            r = 0\n",
    "            c = sent_out.shape[1]\n",
    "            for l in lengths:\n",
    "                if l==curr_length:\n",
    "                    review_batch = torch.cat((review_batch,sent_out[r:r+l,:]))\n",
    "                    r+=l\n",
    "                else:\n",
    "                    diff = curr_length-l\n",
    "                    review_batch = torch.cat((review_batch,sent_out[r:r+l,:],torch.zeros(diff,c)))\n",
    "                    r+=l\n",
    "\n",
    "            review_batch = review_batch.view(len(lengths),-1,c)\n",
    "\n",
    "            print('review batch')\n",
    "            print(review_batch.shape)\n",
    "            output = sentEnc(review_batch,torch.LongTensor(lengths),len(lengths))\n",
    "            \n",
    "            print(output.shape)\n",
    "            \n",
    "            loss = criterion(output.squeeze(),label)\n",
    "            \n",
    "            print(loss)\n",
    "            wordEnc_optimizer.zero_grad()\n",
    "            sentEnc_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            sentEnc_optimizer.step()\n",
    "            wordEnc_optimizer.step()\n",
    "            break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0])\n",
      "hidden_size\n",
      "torch.Size([33, 40])\n",
      "output from word encoder obtained\n",
      "torch.Size([1, 22, 40])\n",
      "review batch\n",
      "torch.Size([4, 6, 40])\n",
      "output from GRU obtained\n",
      "size of hidden state\n",
      "torch.Size([6, 40])\n",
      "linear and tanh transformation done\n",
      "torch.Size([4, 6, 15])\n",
      "torch.Size([1, 4, 2])\n",
      "tensor(0.6865, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "train(wordEnc,sentEnc,train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEnc = wordEncoder(10,15,20,15,0)\n",
    "sentEnc = sentenceEncoder(15,20,15,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,X_lengths,mapped_index = sortbylength(data_train[0],data_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "out = wordEnc(X,X_lengths,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 15])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = torch.cat((out.squeeze(),torch.zeros(1,15))).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 15])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = out_1.view(2,-1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 15])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5392, 0.5036],\n",
       "         [0.5387, 0.5031]]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_enc(out_1,torch.LongTensor([4,3]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 5, 20])\n",
      "tensor(0.6927, grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "train(wordEnc,sentEnc,data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2index.pickle','rb') as fs:\n",
    "    w2i = pickle.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingDataset(fname,w2i):  # dictionary of list of tuples (rev,label)\n",
    "    dataset = {}\n",
    "    with open(fname+'_cleaned') as fs:\n",
    "        for line in fs:\n",
    "            label = int(line[0])\n",
    "            review = line[2:]\n",
    "            temp = review.strip().split('.')\n",
    "            length = len(temp)\n",
    "            if length not in dataset:\n",
    "                dataset[length] = []\n",
    "            encoded_review = text2tensor(temp,w2i)\n",
    "            if len(encoded_review)>0:\n",
    "                dataset[length].append((encoded_review,label))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2tensor(review,w2i):\n",
    "    out = [[w2i[w] for w in sents.split()] for sents in review if len(sents)>0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = creatingDataset('../Data/train.csv', w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBatches(dataset, batch_size):  # generator implementation\n",
    "    batch = []  # return a batch of datapoints based on batch_size\n",
    "    lengths = list(dataset.keys())\n",
    "    lengths.sort()\n",
    "    size = 0\n",
    "    sent_length = []\n",
    "    \n",
    "    for l in lengths[:100]:\n",
    "        for doc in dataset[l]:\n",
    "            batch.append(doc)\n",
    "            sent_length.append(len(doc[0]))\n",
    "            size+=1\n",
    "            if size==batch_size:\n",
    "                yield(batch,sent_length)\n",
    "                batch = []\n",
    "                sent_length = []\n",
    "                size = 0\n",
    "                \n",
    "        yield(batch,sent_length)\n",
    "        batch = []\n",
    "        sent_length = []\n",
    "        size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of sizes:\n",
    "keys = list(train_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2899549\n",
      "2 5740726\n",
      "3 5897990\n",
      "4 3913050\n",
      "5 2479805\n",
      "6 1669319\n",
      "7 1184796\n",
      "8 872828\n",
      "9 663894\n",
      "10 518487\n",
      "11 416298\n",
      "12 337900\n",
      "13 278558\n",
      "14 232642\n",
      "15 195719\n",
      "16 166574\n",
      "17 142636\n",
      "18 122986\n",
      "19 107156\n",
      "20 93563\n",
      "21 81876\n",
      "22 72085\n",
      "23 63604\n",
      "24 56658\n",
      "25 49760\n",
      "26 43882\n",
      "27 39101\n",
      "28 35149\n",
      "29 31613\n",
      "30 27989\n",
      "31 25111\n",
      "32 22792\n",
      "33 20464\n",
      "34 18696\n",
      "35 16859\n",
      "36 15446\n",
      "37 13678\n",
      "38 12562\n",
      "39 11543\n",
      "40 10479\n",
      "41 9574\n",
      "42 8890\n",
      "43 8033\n",
      "44 7472\n",
      "45 6873\n",
      "46 6376\n",
      "47 5855\n",
      "48 5365\n",
      "49 4987\n",
      "50 4649\n",
      "51 4212\n",
      "52 3897\n",
      "53 3599\n",
      "54 3276\n",
      "55 3075\n",
      "56 2830\n",
      "57 2672\n",
      "58 2459\n",
      "59 2258\n",
      "60 2105\n",
      "61 1957\n",
      "62 1832\n",
      "63 1737\n",
      "64 1633\n",
      "65 1612\n",
      "66 1423\n",
      "67 1276\n",
      "68 1284\n",
      "69 1191\n",
      "70 1057\n",
      "71 1071\n",
      "72 989\n",
      "73 917\n",
      "74 905\n",
      "75 815\n",
      "76 748\n",
      "77 770\n",
      "78 647\n",
      "79 634\n",
      "80 609\n",
      "81 566\n",
      "82 574\n",
      "83 503\n",
      "84 472\n",
      "85 449\n",
      "86 404\n",
      "87 387\n",
      "88 371\n",
      "89 387\n",
      "90 378\n",
      "91 357\n",
      "92 311\n",
      "93 315\n",
      "94 270\n",
      "95 268\n",
      "96 280\n",
      "97 243\n",
      "98 242\n",
      "99 220\n",
      "100 196\n",
      "101 196\n",
      "102 173\n",
      "103 211\n",
      "104 184\n",
      "105 159\n",
      "106 157\n",
      "107 196\n",
      "108 149\n",
      "109 130\n",
      "110 114\n",
      "111 152\n",
      "112 131\n",
      "113 103\n",
      "114 115\n",
      "115 94\n",
      "116 116\n",
      "117 117\n",
      "118 100\n",
      "119 101\n",
      "120 98\n",
      "121 85\n",
      "122 79\n",
      "123 87\n",
      "124 104\n",
      "125 76\n",
      "126 63\n",
      "127 84\n",
      "128 66\n",
      "129 70\n",
      "130 47\n",
      "131 48\n",
      "132 59\n",
      "133 52\n",
      "134 53\n",
      "135 54\n",
      "136 57\n",
      "137 64\n",
      "138 45\n",
      "139 44\n",
      "140 56\n",
      "141 43\n",
      "142 49\n",
      "143 38\n",
      "144 35\n",
      "145 37\n",
      "146 33\n",
      "147 37\n",
      "148 44\n",
      "149 45\n",
      "150 25\n",
      "151 38\n",
      "152 29\n",
      "153 33\n",
      "154 29\n",
      "155 47\n",
      "156 29\n",
      "157 23\n",
      "158 20\n",
      "159 28\n",
      "160 27\n",
      "161 25\n",
      "162 34\n",
      "163 24\n",
      "164 22\n",
      "165 18\n",
      "166 24\n",
      "167 19\n",
      "168 18\n",
      "169 25\n",
      "170 21\n",
      "171 19\n",
      "172 19\n",
      "173 23\n",
      "174 12\n",
      "175 16\n",
      "176 16\n",
      "177 17\n",
      "178 11\n",
      "179 14\n",
      "180 17\n",
      "181 17\n",
      "182 16\n",
      "183 11\n",
      "184 18\n",
      "185 14\n",
      "186 10\n",
      "187 9\n",
      "188 10\n",
      "189 6\n",
      "190 17\n",
      "191 6\n",
      "192 21\n",
      "193 14\n",
      "194 8\n",
      "195 9\n",
      "196 7\n",
      "197 14\n",
      "198 5\n",
      "199 10\n",
      "200 11\n",
      "201 9\n",
      "202 11\n",
      "203 7\n",
      "204 7\n",
      "205 8\n",
      "206 10\n",
      "207 6\n",
      "208 11\n",
      "209 8\n",
      "210 6\n",
      "211 9\n",
      "212 5\n",
      "213 10\n",
      "214 10\n",
      "215 9\n",
      "216 11\n",
      "217 5\n",
      "218 6\n",
      "219 6\n",
      "220 5\n",
      "221 9\n",
      "222 5\n",
      "223 8\n",
      "224 4\n",
      "225 10\n",
      "226 4\n",
      "227 2\n",
      "228 6\n",
      "229 3\n",
      "230 7\n",
      "231 5\n",
      "232 13\n",
      "233 10\n",
      "234 7\n",
      "235 3\n",
      "236 1\n",
      "237 2\n",
      "238 5\n",
      "239 4\n",
      "240 5\n",
      "241 5\n",
      "242 4\n",
      "243 2\n",
      "244 6\n",
      "245 6\n",
      "246 4\n",
      "247 4\n",
      "248 9\n",
      "249 4\n",
      "250 6\n",
      "251 2\n",
      "252 2\n",
      "253 7\n",
      "255 6\n",
      "256 1\n",
      "257 3\n",
      "258 3\n",
      "259 4\n",
      "260 6\n",
      "261 3\n",
      "263 2\n",
      "264 5\n",
      "265 6\n",
      "266 1\n",
      "267 6\n",
      "268 1\n",
      "269 6\n",
      "270 2\n",
      "271 2\n",
      "272 1\n",
      "273 5\n",
      "274 1\n",
      "275 2\n",
      "276 3\n",
      "277 4\n",
      "278 2\n",
      "279 3\n",
      "280 1\n",
      "281 2\n",
      "282 1\n",
      "283 2\n",
      "284 1\n",
      "285 3\n",
      "286 1\n",
      "287 5\n",
      "288 5\n",
      "289 1\n",
      "290 1\n",
      "291 2\n",
      "292 2\n",
      "294 2\n",
      "296 3\n",
      "297 1\n",
      "298 2\n",
      "299 3\n",
      "300 3\n",
      "302 3\n",
      "303 1\n",
      "304 2\n",
      "305 1\n",
      "306 2\n",
      "307 4\n",
      "309 1\n",
      "311 2\n",
      "312 1\n",
      "314 1\n",
      "316 1\n",
      "317 1\n",
      "320 2\n",
      "323 2\n",
      "325 1\n",
      "329 1\n",
      "332 2\n",
      "333 1\n",
      "337 1\n",
      "340 1\n",
      "342 3\n",
      "344 2\n",
      "347 1\n",
      "348 1\n",
      "350 1\n",
      "351 1\n",
      "352 2\n",
      "364 1\n",
      "369 1\n",
      "371 1\n",
      "372 1\n",
      "376 1\n",
      "378 1\n",
      "384 5\n",
      "385 1\n",
      "387 1\n",
      "389 1\n",
      "394 2\n",
      "397 1\n",
      "400 1\n",
      "402 1\n",
      "408 1\n",
      "412 1\n",
      "431 2\n",
      "438 1\n",
      "444 1\n",
      "446 1\n",
      "462 1\n",
      "468 1\n",
      "478 1\n",
      "505 1\n",
      "508 1\n",
      "513 1\n",
      "597 1\n",
      "701 1\n",
      "840 1\n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "for k in keys:\n",
    "    print(k,len(train_dataset[k]))\n",
    "    reviews.append(len(train_dataset[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28738514"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 128 128\n",
      "2000 128 128\n",
      "3000 128 128\n",
      "4000 128 128\n",
      "5000 128 128\n",
      "6000 128 128\n",
      "7000 128 128\n",
      "8000 128 128\n",
      "9000 128 128\n",
      "10000 128 128\n",
      "11000 128 128\n",
      "12000 128 128\n",
      "13000 128 128\n",
      "14000 128 128\n",
      "15000 128 128\n",
      "16000 128 128\n",
      "17000 128 128\n",
      "18000 128 128\n",
      "19000 128 128\n",
      "20000 128 128\n",
      "21000 128 128\n",
      "22000 128 128\n",
      "23000 128 128\n",
      "24000 128 128\n",
      "25000 128 128\n",
      "26000 128 128\n",
      "27000 128 128\n",
      "28000 128 128\n",
      "29000 128 128\n",
      "30000 128 128\n",
      "31000 128 128\n",
      "32000 128 128\n",
      "33000 128 128\n",
      "34000 128 128\n",
      "35000 128 128\n",
      "36000 128 128\n",
      "37000 128 128\n",
      "38000 128 128\n",
      "39000 128 128\n",
      "40000 128 128\n",
      "41000 128 128\n",
      "42000 128 128\n",
      "43000 128 128\n",
      "44000 128 128\n",
      "45000 128 128\n",
      "46000 128 128\n",
      "47000 128 128\n",
      "48000 128 128\n",
      "49000 128 128\n",
      "50000 128 128\n",
      "51000 128 128\n",
      "52000 128 128\n",
      "53000 128 128\n",
      "54000 128 128\n",
      "55000 128 128\n",
      "56000 128 128\n",
      "57000 128 128\n",
      "58000 128 128\n",
      "59000 128 128\n",
      "60000 128 128\n",
      "61000 128 128\n",
      "62000 128 128\n",
      "63000 128 128\n",
      "64000 128 128\n",
      "65000 128 128\n",
      "66000 128 128\n",
      "67000 128 128\n",
      "68000 128 128\n",
      "69000 128 128\n",
      "70000 128 128\n",
      "71000 128 128\n",
      "72000 128 128\n",
      "73000 128 128\n",
      "74000 128 128\n",
      "75000 128 128\n",
      "76000 128 128\n",
      "77000 128 128\n",
      "78000 128 128\n",
      "79000 128 128\n",
      "80000 128 128\n",
      "81000 128 128\n",
      "82000 128 128\n",
      "83000 128 128\n",
      "84000 128 128\n",
      "85000 128 128\n",
      "86000 128 128\n",
      "87000 128 128\n",
      "88000 128 128\n",
      "89000 128 128\n",
      "90000 128 128\n",
      "91000 128 128\n",
      "92000 128 128\n",
      "93000 128 128\n",
      "94000 128 128\n",
      "95000 128 128\n",
      "96000 128 128\n",
      "97000 128 128\n",
      "98000 128 128\n",
      "99000 128 128\n",
      "100000 128 128\n",
      "101000 128 128\n",
      "102000 128 128\n",
      "103000 128 128\n",
      "104000 128 128\n",
      "105000 128 128\n",
      "106000 128 128\n",
      "107000 128 128\n",
      "108000 128 128\n",
      "109000 128 128\n",
      "110000 128 128\n",
      "111000 128 128\n",
      "112000 128 128\n",
      "113000 128 128\n",
      "114000 128 128\n",
      "115000 128 128\n",
      "116000 128 128\n",
      "117000 128 128\n",
      "118000 128 128\n",
      "119000 128 128\n",
      "120000 128 128\n",
      "121000 128 128\n",
      "122000 128 128\n",
      "123000 128 128\n",
      "124000 128 128\n",
      "125000 128 128\n",
      "126000 128 128\n",
      "127000 128 128\n",
      "128000 128 128\n",
      "129000 128 128\n",
      "130000 128 128\n",
      "131000 128 128\n",
      "132000 128 128\n",
      "133000 128 128\n",
      "134000 128 128\n",
      "135000 128 128\n",
      "136000 128 128\n",
      "137000 128 128\n",
      "138000 128 128\n",
      "139000 128 128\n",
      "140000 128 128\n",
      "141000 128 128\n",
      "142000 128 128\n",
      "143000 128 128\n",
      "144000 128 128\n",
      "145000 128 128\n",
      "146000 128 128\n",
      "147000 128 128\n",
      "148000 128 128\n",
      "149000 128 128\n",
      "150000 128 128\n",
      "151000 128 128\n",
      "152000 128 128\n",
      "153000 128 128\n",
      "154000 128 128\n",
      "155000 128 128\n",
      "156000 128 128\n",
      "157000 128 128\n",
      "158000 128 128\n",
      "159000 128 128\n",
      "160000 128 128\n",
      "161000 128 128\n",
      "162000 128 128\n",
      "163000 128 128\n",
      "164000 128 128\n",
      "165000 128 128\n",
      "166000 128 128\n",
      "167000 128 128\n",
      "168000 128 128\n",
      "169000 128 128\n",
      "170000 128 128\n",
      "171000 128 128\n",
      "172000 128 128\n",
      "173000 128 128\n",
      "174000 128 128\n",
      "175000 128 128\n",
      "176000 128 128\n",
      "177000 128 128\n",
      "178000 128 128\n",
      "179000 128 128\n",
      "180000 128 128\n",
      "181000 128 128\n",
      "182000 128 128\n",
      "183000 128 128\n",
      "184000 128 128\n",
      "185000 128 128\n",
      "186000 128 128\n",
      "187000 128 128\n",
      "188000 128 128\n",
      "189000 128 128\n",
      "190000 128 128\n",
      "191000 128 128\n",
      "192000 128 128\n",
      "193000 128 128\n",
      "194000 128 128\n",
      "195000 128 128\n",
      "196000 128 128\n",
      "197000 128 128\n",
      "198000 128 128\n",
      "199000 128 128\n",
      "200000 128 128\n",
      "201000 128 128\n",
      "202000 128 128\n",
      "203000 128 128\n",
      "204000 128 128\n",
      "205000 128 128\n",
      "206000 128 128\n",
      "207000 128 128\n",
      "208000 128 128\n",
      "209000 128 128\n",
      "210000 128 128\n",
      "211000 128 128\n",
      "212000 128 128\n",
      "213000 128 128\n",
      "214000 128 128\n",
      "215000 128 128\n",
      "216000 128 128\n",
      "217000 128 128\n",
      "218000 128 128\n",
      "219000 128 128\n",
      "220000 128 128\n",
      "221000 128 128\n",
      "222000 128 128\n",
      "223000 128 128\n",
      "224000 128 128\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for batch,lengths in createBatches(train_dataset,128):\n",
    "    count+=1\n",
    "    if count%1000==0:\n",
    "        print(count,len(batch),len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
